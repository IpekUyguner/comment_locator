{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "analysis_java_files.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "339cuvjJcBVW"
      },
      "source": [
        "Connect to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaXOTQQkV8zG"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovxEfbBZdJBV"
      },
      "source": [
        "**DOWNLOAD DATA**\n",
        "\n",
        "From the link download \"Repositories with more than 50 stars part 2\" (56.8 GB)\n",
        "\n",
        "\n",
        "https://jetbrains.team/p/ccrm/repositories/fl-dataset/files/docs/README.md#download "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5yDT_VidTp6"
      },
      "source": [
        "We only use Java files:\n",
        "\n",
        "- You can only keep \"dataset-open-50-more-2/dataset/v3/languages/Java\" which is around 13 GB\n",
        "- Extract the java files in colab local (reading through from google drive takes more time)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoNF-NOJUwyr"
      },
      "source": [
        "!unzip \"/content/gdrive/My Drive/Java.zip\" -d \"javadata\"\n",
        "dataDir = 'javadata/Java/.java'  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMTAadMcb_iy"
      },
      "source": [
        " ***IMPORT PACKAGES***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3c7vz75Y9Nf"
      },
      "source": [
        "!pip3 install tree_sitter\n",
        "!git clone https://github.com/tree-sitter/tree-sitter-java"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m25Jc8GGBHHk"
      },
      "source": [
        "from tree_sitter import Language, Parser\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj5UrxrhhVNZ"
      },
      "source": [
        "Create python dependency for tree_sitter "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hE2Db50ZHX6"
      },
      "source": [
        "Language.build_library(\n",
        "  # Store the library in the `build` directory\n",
        "  'build/my-languages.so',\n",
        "\n",
        "  # Include one or more languages\n",
        "  [\n",
        "    'tree-sitter-java'\n",
        "  ]\n",
        ")\n",
        "JAVA_LANGUAGE = Language('build/my-languages.so', 'java')\n",
        "parser = Parser()\n",
        "parser.set_language(JAVA_LANGUAGE)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FFLZGsMhkNu"
      },
      "source": [
        "# **Traversing AST tree of java files**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TFtThVvZ2IP"
      },
      "source": [
        "def traverse_tree(tree):\n",
        "  cursor = tree.walk()\n",
        "\n",
        "  reached_root = False\n",
        "  while reached_root == False:\n",
        "    \n",
        "    yield cursor.node\n",
        "\n",
        "    if cursor.goto_first_child():\n",
        "      continue\n",
        "\n",
        "    if cursor.goto_next_sibling():\n",
        "      continue\n",
        "\n",
        "    retracing = True\n",
        "    while retracing:\n",
        "      if not cursor.goto_parent():\n",
        "        retracing = False\n",
        "        reached_root = True\n",
        "\n",
        "      if cursor.goto_next_sibling():\n",
        "        retracing = False"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv8fCKwZbTQN"
      },
      "source": [
        "content = []\n",
        "c=0\n",
        "for root, dirs, files in tqdm(os.walk(dataDir), position=0):\n",
        "  for file in files:\n",
        "    file_name = os.path.join(root, file)\n",
        "\n",
        "    if os.path.isfile(file_name):\n",
        "      try:\n",
        "        number_of_comment = 0\n",
        "        file = open(file_name, mode='r')\n",
        "        number_of_lines = len(file.readlines())\n",
        "        file.seek(0)\n",
        "        all_of_it = file.read()\n",
        "        file.close()\n",
        "        ast = parser.parse(bytes(all_of_it, \"utf8\"))\n",
        "\n",
        "        for node in traverse_tree(ast):\n",
        "          if node.type == \"comment\":\n",
        "            number_of_comment +=  1\n",
        "\n",
        "        content.append((number_of_lines,number_of_comment))\n",
        "        c +=1\n",
        "        print(c)\n",
        "      except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-h9DHCLnGxg"
      },
      "source": [
        "#**Remove outliers**\n",
        "\n",
        "From around 1.6 million files, only few thousand files are with more than 1K comments and bigger than 5K lines, we can so ignore them as follow:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6pzgepNfPoh"
      },
      "source": [
        "#total number of java files:\n",
        "file_count = len(content)\n",
        "\n",
        "print(\"Total number of Java Files: \" + str(file_count))\n",
        "#total number of files with number of comments>1000\n",
        "#print(\"Total number of Java Files with number of comments more than 1K: \" + str(outliers))\n",
        "#From around 1.6 million files, only around 200 files are with more than 1k comments, we can so ignore them as follow:\n",
        "\n",
        "#print(\"Total number of Java Files with length > 10K line: \" + str(outliers))\n",
        "#From around 1.6 million files, only around  files are with bigger than 5K lines, we can so ignore them as follow:\n",
        "content_filtered = [x for x in content if x[0]<=5000 and x[1]<1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns1jhfwu1R6x"
      },
      "source": [
        "# **GRAPHS PLOTTING**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjnqgMOA1c14"
      },
      "source": [
        "Graph for how many files exists per spesific number of comments range\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5IZLFiQctxd"
      },
      "source": [
        "comment_count_per_file_list = [x[1] for x in content_filtered]\n",
        "\n",
        "bins = [0, 100, 200, 300, 400, 500 ,600,700,800,900,1000]\n",
        "plt.hist(comment_count_per_file_list, bins, histtype='bar', rwidth=0.7)\n",
        "plt.xlabel('Number of comments')\n",
        "plt.ylabel('Number of files')\n",
        "plt.title(\"Count of files given number of comments\")\n",
        "plt.savefig(\"a.png\")\n",
        "\n",
        "###(1e6 =10^6)###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_UCF6n6imfj"
      },
      "source": [
        "\n",
        "nocom = len([x for x in comment_count_per_file_list if x == 0] )\n",
        "com = len([x for x in comment_count_per_file_list if x != 0 ])\n",
        "\n",
        "bins = [nocom, com]\n",
        "plt.bar([\"number of files without any comment\", \"number of files with at least 1 comments\"], bins, width=0.4)\n",
        "plt.savefig('b.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiC3P4P4cnyl"
      },
      "source": [
        "percent = lambda part, whole: float(part) * 100 / float(whole)\n",
        "percents_arr = []\n",
        "size_files = []\n",
        "for line in content_filtered:\n",
        "  try:\n",
        "    number_comment = line[1]\n",
        "    size= line[0]\n",
        "\n",
        "    size_files.append(size)\n",
        "    percents_arr.append(percent(number_comment,size))\n",
        "  except:\n",
        "    pass\n",
        "plt.xlabel('% of comments in file')\n",
        "plt.ylabel('Count')\n",
        "plt.title(\"\")\n",
        "bins = [0,10,20,30,40,50,60,70,80,90,100]\n",
        "plt.hist(percents_arr, bins, histtype='bar', rwidth=0.7)\n",
        "plt.savefig('c.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sxUsfDQiU9w"
      },
      "source": [
        "from pyparsing import ParseExpression\n",
        "import plotly.express as px\n",
        "#! pip install  -U kaleido\n",
        "comment_count_per_file_list = []\n",
        "size_files = []\n",
        "\n",
        "for line in content_filtered:\n",
        "  try:\n",
        "    number_comment = line[1]\n",
        "    size= line[0]\n",
        "    if (number_comment)>0: \n",
        "      size_files.append(size)\n",
        "      comment_count_per_file_list.append(number_comment)\n",
        "  except:\n",
        "      pass\n",
        "\n",
        "fig = px.scatter(x=size_files,y=comment_count_per_file_list, width=1000, height=800, labels={'x':'number of line in file', 'y':'number of comment in the file'})\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRJhhW-CL0bF"
      },
      "source": [
        "## **THIS APPROACH IS ONLY APPROXIMATION FOR COUNTING COMMENTS IN A GIVEN CHUNK**\n",
        "\n",
        "- Create code chunks based on empty lines\n",
        "\n",
        "- If a line contains \"comment special character, assume it is comment:\n",
        "  This way may result some non-comment line as if they are comment (such as in URL links http:// but it is an approximation that is fast)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDkubXQUQfin"
      },
      "source": [
        "result = []\n",
        "c = 0\n",
        "def averageLen(lst):\n",
        "    lengths = [len(i) for i in lst]\n",
        "    return 0 if len(lengths) == 0 else (float(sum(lengths)) / len(lengths)) \n",
        "\n",
        "for root, dirs, files in tqdm(os.walk(dataDir), position=0):\n",
        "  for file in files:\n",
        "    file_name = os.path.join(root, file)\n",
        "\n",
        "    if os.path.isfile(file_name):\n",
        "      try:\n",
        "        chunks_list =[]\n",
        "        chunks = []\n",
        "        comment_count = 0\n",
        "        comment = False\n",
        "        count = 0\n",
        "        file = open(file_name, mode='r')\n",
        "        lines = file.readlines()\n",
        "        for line in lines:\n",
        "          if not line.split(): #start a chunk\n",
        "            chunks_list.append(chunks)\n",
        "            chunks = []\n",
        "            if comment:\n",
        "              comment_count += 1\n",
        "              comment =False\n",
        "          else:\n",
        "            chunks.append(line)\n",
        "            if \"//\" in line or '/*' in line:\n",
        "              comment = True\n",
        "        c +=1   \n",
        "        print(c)\n",
        "        result.append((file_name , len(chunks_list), comment_count, averageLen(chunks_list)))\n",
        "      except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbYe9mfRQnF-"
      },
      "source": [
        "from pyparsing import ParseExpression\n",
        "import plotly.express as px\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "result_without_filename = [(x[1], x[2]) for x in result]\n",
        "\n",
        "for line in result_without_filename:\n",
        "  count_chunks = line[0]\n",
        "  count_comments = line[1]\n",
        "  x.append(count_chunks)\n",
        "  y.append(count_comments)\n",
        "  \n",
        "fig = px.scatter(x=x,y=y, width=1000, height=800, labels={'x':'number of chunks in file', 'y':'number of commented chunks'})\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0zVUD0g-bGv"
      },
      "source": [
        "percent = lambda part, whole: float(part) * 100 / float(whole)\n",
        "percents_arr = []\n",
        "size_files = []\n",
        "for line in result_without_filename:\n",
        "  number_comment = line[1]\n",
        "  size= line[0]\n",
        "  size_files.append(size)\n",
        "  if size>0:\n",
        "    percents_arr.append(percent(number_comment,size))\n",
        "\n",
        "plt.xlabel('Percentage of commented chunks in files')\n",
        "plt.ylabel('Count')\n",
        "plt.title(\"\")\n",
        "bins = [0,10,20,30,40,50,60,70,80,90,100]\n",
        "plt.hist(percents_arr, bins, histtype='bar', rwidth=0.7)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-9jQ0Ze_k5O"
      },
      "source": [
        "lis = [(x[3]) for x in result]\n",
        "plt.xlabel('Average length of chunks in files')\n",
        "plt.ylabel('Count')\n",
        "plt.title(\"\")\n",
        "bins = [0,10,20,30,40,50,60,70,80,90,100]\n",
        "plt.hist(lis, bins, histtype='bar', rwidth=0.7)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}